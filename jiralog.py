import os
import json
import requests
from datetime import datetime, timezone
import re
import argparse
import sys
import math  # –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç –¥–ª—è –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è
from colorama import Fore, Back, Style, init
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

init(autoreset=True)

RED, YEL, CYN, GRN, BLU = (
    Fore.LIGHTRED_EX, Fore.LIGHTYELLOW_EX, Fore.LIGHTCYAN_EX,
    Fore.LIGHTGREEN_EX, Fore.LIGHTBLUE_EX,
)
WHT  = Fore.LIGHTWHITE_EX
BOLD = Style.BRIGHT
BBLU = Back.BLUE
BRST = Back.RESET

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Jira API
JIRA_BASE_URL = os.environ.get('JIRA_BASE_URL')
JIRA_USERNAME = os.environ.get('JIRA_USERNAME')
JIRA_API_TOKEN = os.environ.get('JIRA_API_TOKEN')
if not JIRA_BASE_URL or not JIRA_USERNAME or not JIRA_API_TOKEN:
    print(f"{RED}‚ùå –û—à–∏–±–∫–∞: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è JIRA_BASE_URL, JIRA_USERNAME –∏ JIRA_API_TOKEN.")
    exit(1)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
HEADERS = {
    'Authorization': f'{requests.auth._basic_auth_str(JIRA_USERNAME, JIRA_API_TOKEN)}',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
LOGS_DIR = os.path.join(SCRIPT_DIR, 'logs')
REPORTS_DIR = os.path.join(SCRIPT_DIR, 'reports')
os.makedirs(LOGS_DIR, exist_ok=True)
os.makedirs(REPORTS_DIR, exist_ok=True)

# –ë–ª–æ–∫ —Ñ—É–Ω–∫—Ü–∏–π
def get_emoji(num):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–æ–¥–∂–∏ –¥–ª—è –Ω–æ–º–µ—Ä–∞."""
    emojis = ['1Ô∏è‚É£', '2Ô∏è‚É£', '3Ô∏è‚É£', '4Ô∏è‚É£', '5Ô∏è‚É£', '6Ô∏è‚É£', '7Ô∏è‚É£', '8Ô∏è‚É£', '9Ô∏è‚É£', 'üîü']
    if 1 <= num <= 10:
        return emojis[num - 1]
    else:
        return f"[{num}]"  # fallback –¥–ª—è —á–∏—Å–µ–ª > 10

def select_file():
    """–í—ã–±–∏—Ä–∞–µ—Ç JSON —Ñ–∞–π–ª –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞."""
    files = [f for f in os.listdir(LOGS_DIR) if f.endswith('.json')]
    if not files:
        print(f"{RED}‚ùå –ù–µ—Ç JSON —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ logs/.")
        return None

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ –¥–∞—Ç–µ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è DESC (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏), —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å –¥–∞—Ç–æ–π –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    files_with_date = []
    files_without_date = []
    for f in files:
        file_path = os.path.join(LOGS_DIR, f)
        date = parse_date_from_filename(file_path)
        if date is not None:
            files_with_date.append((date, f))
        else:
            files_without_date.append((None, f))

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å –¥–∞—Ç–æ–π –ø–æ –¥–∞—Ç–µ DESC
    files_with_date.sort(key=lambda x: x[0], reverse=True)
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –¥–∞—Ç—ã –ø–æ –∏–º–µ–Ω–∏ ASC
    files_without_date.sort(key=lambda x: x[1])

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º: —Å–Ω–∞—á–∞–ª–∞ —Å –¥–∞—Ç–∞–º–∏, –ø–æ—Ç–æ–º –±–µ–∑
    sorted_files = files_with_date + files_without_date

    print(f"{YEL}üìÅ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    for i, (date, f) in enumerate(sorted_files, 1):
        emoji = get_emoji(i)
        print(f" {emoji}  {f}")
    try:
        choice = int(input(" ‚û°Ô∏è  –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞: ")) - 1
        if 0 <= choice < len(sorted_files):
            selected_file = sorted_files[choice][1]
            return os.path.join(LOGS_DIR, selected_file)
        else:
            print(f"{RED}‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä.")
            return None
    except ValueError:
        print(f"{RED}‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ.")
        return None

def load_json(file_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON –∏–∑ —Ñ–∞–π–ª–∞."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"{RED}‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ JSON: {e}")
        return None

def parse_date_from_filename(file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (—Ñ–æ—Ä–º–∞—Ç: DD.MM.YYYY)."""
    filename = os.path.basename(file_path)
    match = re.search(r'(\d{2}\.\d{2}\.\d{4})', filename)
    if match:
        date_str = match.group(1)
        try:
            return datetime.strptime(date_str, '%d.%m.%Y').date()
        except ValueError:
            pass
    print(f"{YEL}‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.")
    confirm = input("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É? (y/n): ").lower()
    if confirm != 'y':
        print(f"{RED}‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞.")
        exit(1)
    return datetime.now(timezone.utc).date()

def parse_issue_id(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ISSUE_ID –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, RS-1)."""
    match = re.search(r'([A-Z]+-\d+)', text)
    return match.group(1) if match else None

def parse_task_text(text):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏ –±–µ–∑ issue_key."""
    issue_id = parse_issue_id(text)
    return text.replace(issue_id, '').strip() if issue_id else text.strip()

def parse_task_time(lap):
    """–ü–∞—Ä—Å–∏—Ç –≤—Ä–µ–º—è –∑–∞–¥–∞—á–∏: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç timeSpentSeconds."""
    return lap['diff'] // 1000

def format_time(seconds):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—É–Ω–¥—ã –≤ 'HH:MM'."""
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    return f"{hours:02d}:{minutes:02d}"

def extract_text_from_adf(adf):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ Atlassian Document Format (ADF)."""
    try:
        return adf['content'][0]['content'][0]['text']
    except (KeyError, IndexError, TypeError):
        return ""

def get_existing_worklogs(issue_key):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ worklogs –¥–ª—è issue."""
    url = f"{JIRA_BASE_URL}/rest/api/3/issue/{issue_key}/worklog"
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code == 200:
            return response.json().get('worklogs', [])
        else:
            print(f"{RED}‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è worklogs –¥–ª—è {issue_key}: HTTP {response.status_code}")
            return []
    except requests.RequestException as e:
        print(f"{RED}‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {issue_key}: {e}")
        return []

def worklog_exists(issue_key, comment_text, started):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ worklog —Å —Ç–∞–∫–∏–º comment –∏ started (–≤ —Ä–∞–º–∫–∞—Ö –¥–Ω—è)."""
    worklogs = get_existing_worklogs(issue_key)
    return any(wl.get('started') == started and extract_text_from_adf(wl.get('comment')) == comment_text for wl in worklogs)

def add_worklog(issue_key, started, time_spent_seconds, comment_text, dry_run=False):
    """–î–æ–±–∞–≤–ª—è–µ—Ç worklog –≤ Jira. –í dry-run —Ä–µ–∂–∏–º–µ —Å–∏–º—É–ª–∏—Ä—É–µ—Ç."""
    comment_adf = {
        "type": "doc",
        "version": 1,
        "content": [
            {
                "type": "paragraph",
                "content": [
                    {
                        "type": "text",
                        "text": comment_text
                    }
                ]
            }
        ]
    }
    if dry_run:
        return f"üîç Worklog –¥–ª—è {issue_key}: {comment_text} ({format_time(time_spent_seconds)})"
    url = f"{JIRA_BASE_URL}/rest/api/3/issue/{issue_key}/worklog"
    data = {
        "started": started,
        "timeSpentSeconds": time_spent_seconds,
        "comment": comment_adf
    }
    try:
        response = requests.post(url, headers=HEADERS, json=data, timeout=10)
        return response.status_code == 201
    except requests.RequestException as e:
        print(f"{RED}‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è worklog –¥–ª—è {issue_key}: {e}")
        return False

def process_lap(lap, reports, total_logged_seconds, dry_run_messages, dry_run=False):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω lap: –ø–∞—Ä—Å–∏—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç worklog –µ—Å–ª–∏ –Ω—É–∂–Ω–æ."""
    text = lap['text']
    issue_id = parse_issue_id(text)
    if not issue_id:
        reports['failed'].append(f"–ù–µ –Ω–∞–π–¥–µ–Ω ISSUE_ID –≤: {text}")
        return
    task_text = parse_task_text(text)
    time_spent_seconds = parse_task_time(lap)
    if time_spent_seconds <= 0 or not task_text.strip():
        reports['failed'].append(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {issue_id}: –≤—Ä–µ–º—è={time_spent_seconds}, —Ç–µ–∫—Å—Ç='{task_text}'")
        return
    if worklog_exists(issue_id, task_text, started):
        reports['skipped'].append(f"Worklog —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–ª—è {issue_id}: {task_text}")
        return
    result = add_worklog(issue_id, started, time_spent_seconds, task_text, dry_run)
    if dry_run:
        dry_run_messages.append(result)
        reports['success'].append(f"–î–æ–±–∞–≤–ª–µ–Ω worklog –¥–ª—è {issue_id}: {task_text} ({format_time(time_spent_seconds)})")
        total_logged_seconds[0] += time_spent_seconds
    elif result:
        reports['success'].append(f"–î–æ–±–∞–≤–ª–µ–Ω worklog –¥–ª—è {issue_id}: {task_text} ({format_time(time_spent_seconds)})")
        total_logged_seconds[0] += time_spent_seconds
    else:
        reports['failed'].append(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è worklog –¥–ª—è {issue_id}: {task_text}")

def group_laps(laps):
    """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç laps –ø–æ (ISSUE_ID, —Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏), —Å—É–º–º–∏—Ä—É—è –≤—Ä–µ–º—è. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (grouped, invalid)."""
    grouped = {}
    invalid = []
    for lap in laps:
        issue_id = parse_issue_id(lap['text'])
        if not issue_id:
            invalid.append(lap)
            continue
        task_text = parse_task_text(lap['text'])
        key = (issue_id, task_text)
        if key not in grouped:
            grouped[key] = {'text': lap['text'], 'diff': 0}
        grouped[key]['diff'] += lap['diff']
    return list(grouped.values()), invalid

# –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
parser = argparse.ArgumentParser(description="–ó–∞–≥—Ä—É–∑–∫–∞ worklog –≤ Jira –∏–∑ JSON —Ñ–∞–π–ª–∞.")
parser.add_argument('--dry-run', action='store_true', help="–ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ dry-run (—Å–∏–º—É–ª—è—Ü–∏—è –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π)")
args = parser.parse_args()
dry_run = args.dry_run

# –ò–Ω—Ç—Ä–æ
logo = [
    "     ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ",
    "     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù ",
    "     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ñà‚ïó",
    "‚ñà‚ñà   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë",
    "‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù",
    " ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ",
]
WIDTH = 45
INNER = WIDTH * 2 - 5  # —à–∏—Ä–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: (WIDTH √ó 2col_per_‚ú®) - ‚ú®(2) - space(1) - ‚ú®(2)
border = f"{YEL}" + "‚ú®" * WIDTH
print(border)
max_logo_w = max(len(line) for line in logo)
logo_inner_w = max_logo_w + 4
logo_left  = (INNER - logo_inner_w) // 2
logo_right = INNER - logo_left - logo_inner_w
_logo_row = f"{YEL}‚ú®{BBLU}{' ' * (INNER + 1)}{BRST}{YEL}‚ú®"
print(_logo_row)
for line in logo:
    inner = f"  {line:<{max_logo_w}}  "
    print(f"{YEL}‚ú®{BBLU} {' ' * logo_left}{WHT}{inner}{' ' * logo_right}{BRST}{YEL}‚ú®")
print(_logo_row)
print(f"{YEL}‚ú®{BBLU} {'':{INNER}}{BRST}{YEL}‚ú®")
print(f"{YEL}‚ú®{BBLU} {WHT}–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –≤–æ–ª—à–µ–±–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ worklog –≤ Atlassian Jira!               {BRST}{YEL}‚ú®")
print(f"{YEL}‚ú®{BBLU} {WHT}–≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –ª–µ–≥–∫–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –∏–∑ JSON —Ñ–∞–π–ª–∞.   {BRST}{YEL}‚ú®")
print(f"{YEL}‚ú®{BBLU} {WHT}–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π dry-run, –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ –∏ —è—Ä–∫–æ–≥–æ —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞.                        {BRST}{YEL}‚ú®")
print(f"{YEL}‚ú®{BBLU} {'':{INNER}}{BRST}{YEL}‚ú®")
print(f"{YEL}‚ú®{BBLU} {BOLD}{WHT}{'–ú–∞–≥–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è! ü™Ñ':^{INNER - 1}}{BRST}{YEL}‚ú®")
print(border)
print()

# –ó–∞–≥—Ä—É–∑–∫–∞ JSON
file_path = select_file()
if not file_path:
    exit(1)
data = load_json(file_path)
if not data:
    exit(1)

# –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º start_time –∫–∞–∫ 6:00 UTC —Ç–æ–≥–æ –¥–Ω—è
file_date = parse_date_from_filename(file_path)
start_time = datetime.combine(file_date, datetime.min.time(), tzinfo=timezone.utc).replace(hour=6)
started = start_time.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + '+0000'

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∏ —Å—É–º–º—ã –≤—Ä–µ–º–µ–Ω–∏
reports = {'success': [], 'failed': [], 'skipped': []}
total_logged_seconds = [0]
dry_run_messages = []

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ laps
grouped_laps, invalid_laps = group_laps(data['laps'])
for lap in invalid_laps:
    reports['failed'].append(f"–ù–µ –Ω–∞–π–¥–µ–Ω ISSUE_ID –≤: {lap['text']}")

total = len(grouped_laps)
for i, lap in enumerate(grouped_laps, 1):
    process_lap(lap, reports, total_logged_seconds, dry_run_messages, dry_run)
    sys.stdout.write(f"\n\r{YEL} üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞: {i}/{total} –∑–∞–¥–∞—á ")
    sys.stdout.flush()
print()

# –í—ã–≤–æ–¥ dry-run —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
if dry_run:
    print(f"{CYN}üîç Dry-run —Å–∏–º—É–ª—è—Ü–∏—è:")
    for msg in dry_run_messages:
        print(f"{CYN}{msg}")
    print()

# –û—Ç—á–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π (—É—Å–ø–µ—Ö/–ø—Ä–æ–≤–∞–ª/–µ—Å—Ç—å –æ—à–∏–±–∫–∏)
success_count = len(reports['success'])
failed_count = len(reports['failed'])
skipped_count = len(reports['skipped'])

if failed_count == 0 and skipped_count == 0:
    global_status = f"{GRN}‚úÖ –£—Å–ø–µ—Ö"
elif success_count > 0:
    global_status = f"{YEL}‚ö†Ô∏è –ï—Å—Ç—å –æ—à–∏–±–∫–∏"
else:
    global_status = f"{RED}‚ùå –ü—Ä–æ–≤–∞–ª"

mode = "DRY-RUN" if dry_run else "REAL"
print(f"\n{YEL}üìä –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç ({mode}): {global_status}")
print(f"{CYN}üìÖ –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ–≥–æ –¥–Ω—è: {started}")
print(f"{BLU}üßÆ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total}, –£—Å–ø–µ—à–Ω–æ: {success_count}, –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}, –û—à–∏–±–æ–∫: {failed_count}")
print(f"{GRN}üïí –û–±—â–∞—è —Å—É–º–º–∞ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏: {format_time(total_logged_seconds[0])}")

# –û—Ç—á–µ—Ç –ø–æ –∑–∞–ø–∏—Å—è–º issues (—É—Å–ø–µ—Ö/–ø—Ä–æ–≤–∞–ª)
print(f"\n{YEL}üìù –û—Ç—á–µ—Ç –ø–æ –∑–∞–ø–∏—Å—è–º:")
for item in reports['success']:
    print(f"{GRN}‚úÖ –£—Å–ø–µ—Ö: {item}")
for item in reports['skipped']:
    print(f"{YEL}‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {item}")
for item in reports['failed']:
    print(f"{RED}‚ùå –û—à–∏–±–∫–∞: {item}")

# –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª
save_report = input("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª? (y/n): ").lower() == 'y'
if save_report:
    report_filename = os.path.join(REPORTS_DIR, f"{file_date.strftime('%d.%m.%Y')}_report.txt")
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç ({mode}): {'–£—Å–ø–µ—Ö' if failed_count == 0 and skipped_count == 0 else '–ï—Å—Ç—å –æ—à–∏–±–∫–∏' if success_count > 0 else '–ü—Ä–æ–≤–∞–ª'}\n")
        f.write(f"–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ–≥–æ –¥–Ω—è: {started}\n")
        f.write(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total}, –£—Å–ø–µ—à–Ω–æ: {success_count}, –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}, –û—à–∏–±–æ–∫: {failed_count}\n")
        f.write(f"–û–±—â–∞—è —Å—É–º–º–∞ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏: {format_time(total_logged_seconds[0])}\n\n")
        f.write("–û—Ç—á–µ—Ç –ø–æ –∑–∞–ø–∏—Å—è–º:\n")
        for item in reports['success']:
            f.write(f"–£—Å–ø–µ—Ö: {item}\n")
        for item in reports['skipped']:
            f.write(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: {item}\n")
        for item in reports['failed']:
            f.write(f"–û—à–∏–±–∫–∞: {item}\n")
    print(f"{GRN}üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_filename}")